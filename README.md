This project implements a Text-to-Image Visual Storytelling System using diffusion-based generative models, specifically Stable Diffusion v1.5, to synthesize a single representative image from long-form narrative text. The system employs a Flask-based Python backend to perform text conditioning and image generation via the Hugging Face diffusers library and PyTorch, while a custom HTML/CSS/JavaScript frontend communicates with the backend using RESTful APIs for real-time user interaction. The architecture cleanly separates model inference and presentation logic, enabling scalable deployment and easy extensibility for multi-image generation, scene-wise rendering, or multimedia storytelling applications.
